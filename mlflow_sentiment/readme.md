# Flipkart Sentiment Analysis â€“ End-to-End MLOps Pipeline

This project demonstrates a **production-style MLOps workflow** for sentiment analysis using real-world tools such as **scikit-learn, MLflow, and Prefect**. The focus is not just on model accuracy, but on **experiment tracking, model registry, orchestration, and reproducibility**.

---

## ğŸ“Œ Project Overview

The goal of this project is to build a sentiment classification model for Flipkart product reviews and manage the full ML lifecycle:

* Text preprocessing and feature engineering
* Model training and evaluation
* Experiment tracking with MLflow
* Model registration, tagging, and stage promotion
* Workflow orchestration with Prefect
* Monitoring runs via MLflow UI and Prefect Dashboard

---

## ğŸ§  Model Details

* **Algorithm**: Logistic Regression
* **Vectorization**: TF-IDF (unigrams + bigrams)
* **Text Processing**:

  * Cleaning
  * Tokenization
  * Porter Stemming
* **Evaluation Metrics**:

  * Accuracy
  * Precision
  * Recall
  * F1-score (used for best model selection)

---

## ğŸ› ï¸ Tech Stack

* Python
* scikit-learn
* pandas, numpy
* NLTK
* MLflow
* Prefect 2.x
* Matplotlib

---

## ğŸ“‚ Project Structure

```
mlflow_sentiment/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ clean_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ experimentation.ipynb
â”‚
â”œâ”€â”€ workflow.py              # Prefect workflow
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ mlruns/                  # MLflow tracking directory
```

---

## ğŸ”¬ Experiment Tracking (MLflow)

MLflow is used to track:

* Model hyperparameters
* Preprocessing choices
* Evaluation metrics
* Artifacts (TF-IDF vectorizer, trained model)

### Logged Metrics

* Accuracy
* Precision (weighted)
* Recall (weighted)
* F1-score (weighted)

Metric plots are visualized directly in the **MLflow UI**.

---

## ğŸ† Model Registry & Versioning

The best-performing model (based on **F1-score**) is:

* Registered in **MLflow Model Registry**
* Tagged with metadata (algorithm, preprocessing, dataset version)
* Promoted to stages such as:

  * `Staging`
  * `Production`

This enables controlled model lifecycle management.

---

## ğŸ”„ Workflow Orchestration (Prefect)

A Prefect flow is used to orchestrate the training pipeline:

### Key Tasks

* Load dataset
* Preprocess text
* Vectorize data
* Train model
* Evaluate metrics
* Log results to MLflow

### Why Prefect?

* Task-level retries
* Clear logging
* Visual DAG
* Easy scheduling
* Production-grade orchestration

---

## â° Scheduling

The Prefect workflow can be scheduled (e.g., daily retraining) using:

* Prefect deployments
* Cron or interval schedules

The flow execution and task states can be monitored via the **Prefect Dashboard**.

---

## ğŸ“Š Dashboards

* **MLflow UI**: Experiment comparison, metrics, artifacts, model registry
* **Prefect UI**: Flow runs, retries, logs, and task-level status

Screenshots of both dashboards are included in the project documentation.

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start MLflow UI

```bash
mlflow ui
```

### 3ï¸âƒ£ Start Prefect Server

```bash
prefect server start
```

### 4ï¸âƒ£ Run the workflow

```bash
python workflow.py
```

---

## ğŸš€ Key Learnings

* Proper experiment tracking is critical for reproducibility
* Model registry enables safe promotion to production
* Relative paths break in orchestration â€” absolute paths matter
* Prefect provides clear visibility and reliability for ML pipelines

---

## ğŸ“Œ Future Improvements

* Add hyperparameter tuning with multiple runs
* Add data validation checks
* Integrate model inference pipeline
* Deploy model as an API

---

## ğŸ‘¤ Author

Built as part of a hands-on **MLOps learning project** focused on real-world tooling and best practices.
